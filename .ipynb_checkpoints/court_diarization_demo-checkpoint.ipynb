{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from hparam import hparam as hp\n",
    "from speech_embedder_net import SpeechEmbedder\n",
    "from VAD_segments import VAD_chunk\n",
    "import scipy.stats as stats\n",
    "from dvector_create import concat_segs,get_STFTs, align_embeddings\n",
    "from dvector_vis import visualization\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization\n",
    "embedder_net = SpeechEmbedder()\n",
    "embedder_net.load_state_dict(torch.load('/Users/junhengwang/coop/court_data/ckpt/ckpt_epoch_180_batch_id_1324.pth'))\n",
    "embedder_net.eval()\n",
    "train_sequence = []\n",
    "train_cluster_id = []\n",
    "df = pandas.read_csv(\"/Users/junhengwang/coop/court_data/court_csvs/02975.csv\", delimiter=',')\n",
    "mp3_file = '/Users/junhengwang/coop/court_data/2900_mp3/2975.mp3'\n",
    "tmp_dir = './tmp/'\n",
    "shutil.rmtree(tmp_dir)\n",
    "os.makedirs(tmp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    }
   ],
   "source": [
    "### Concatenate intervals\n",
    "concat_df = []\n",
    "cur_speaker = df.iloc[0]['speaker']\n",
    "cur_start = df.iloc[0]['start_time']\n",
    "cur_end = df.iloc[0]['stop_time']\n",
    "for index, row in df.iterrows():\n",
    "    if row['speaker'] == cur_speaker:\n",
    "        cur_end = row['stop_time']\n",
    "    else:\n",
    "        concat_df.append({'speaker':cur_speaker, 'start_time':cur_start, 'stop_time':cur_end })\n",
    "        cur_speaker = row['speaker']\n",
    "        cur_start = row['start_time']\n",
    "        cur_end = row['stop_time']\n",
    "else:\n",
    "    concat_df.append({'speaker':cur_speaker, 'start_time':cur_start, 'stop_time':cur_end })\n",
    "print(len(concat_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate ffmpeg commands\n",
    "ffm_command_path = tmp_dir + 'ffm_court.txt'\n",
    "ffm_file = open(ffm_command_path,'w')\n",
    "#for index, row in df.iterrows():\n",
    "for index, row in enumerate(concat_df):\n",
    "    start = float(row['start_time'])\n",
    "    duration = float(row['stop_time']) - start \n",
    "    if duration < 2: continue # skip it if it is too short\n",
    "    audio_file = tmp_dir + str(index) + '.wav'\n",
    "    bashCommand = \"ffmpeg -ss \" + str(round(start,2)) + \" -t \" + str(round(duration,2)) + \" -i \" + mp3_file + ' -y -ar 16000 ' +  audio_file\n",
    "    ffm_file.write(bashCommand + '\\n')\n",
    "ffm_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9065175fb66c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbashCommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"parallel -j 50 :::: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mffm_command_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbashCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    773\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0;31m# Data format: \"exception name:hex errno:description\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;31m# Pickle is not used; it is complex and involves memory allocation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m             \u001b[0;31m# errpipe_write must not be in the standard io 0, 1, or 2 fd range.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mlow_fds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 24] Too many open files"
     ]
    }
   ],
   "source": [
    "### Run ffmpeg in parallel\n",
    "import subprocess\n",
    "bashCommand = \"parallel -j 50 :::: \" + ffm_command_path\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "print(output)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create dvector for each audio\n",
    "import re\n",
    "def create_dvector():\n",
    "    audio_files = sorted(glob.glob(tmp_dir + '*.wav'), key=lambda x:int(os.path.basename(x)[:-4]))\n",
    "    vis_file = open(tmp_dir + \"visualization.csv\",\"a+\")\n",
    "    for audio_file in tqdm(audio_files):\n",
    "        speaker_name = re.sub('[^A-Za-z0-9]+','', concat_df[int(os.path.basename(audio_file)[:-4])]['speaker'])\n",
    "        try:\n",
    "            times, segs = VAD_chunk(2, audio_file)\n",
    "        except:\n",
    "            print(audio_file + ' is broken')\n",
    "            continue\n",
    "        if segs == []:\n",
    "            print('No voice activity detected in ' + audio_file)\n",
    "            continue\n",
    "        concat_seg = concat_segs(times, segs)\n",
    "        STFT_frames = get_STFTs(concat_seg)\n",
    "        if not STFT_frames: \n",
    "            print('No STFT frames extracted in ' + audio_file)\n",
    "            continue\n",
    "        STFT_frames = np.stack(STFT_frames, axis=2)\n",
    "        STFT_frames = torch.tensor(np.transpose(STFT_frames, axes=(2,1,0)))\n",
    "        embeddings = embedder_net(STFT_frames) ### slow\n",
    "        aligned_embeddings = align_embeddings(embeddings.detach().numpy())\n",
    "        train_sequence.append(aligned_embeddings)\n",
    "        for embedding in aligned_embeddings:\n",
    "            train_cluster_id.append(speaker_name)\n",
    "        ### save npz for visulization, may need to clean csv first\n",
    "        for index, emb in enumerate(aligned_embeddings):\n",
    "            save_path = tmp_dir + str(speaker_name) + str(index) + '.npz'\n",
    "            save_sequence = np.array([emb])\n",
    "            save_id = np.array([speaker_name] * len(aligned_embeddings))\n",
    "            np.savez(save_path, train_sequence=save_sequence, train_cluster_id=np.array([speaker_name]))\n",
    "            vis_file.write(save_path + '\\n')\n",
    "    vis_file.close()\n",
    "#%prun create_dvector()\n",
    "create_dvector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving dvectors\n",
    "train_sequence = np.concatenate(train_sequence,axis=0)\n",
    "train_cluster_id = np.asarray(train_cluster_id)\n",
    "np.save('court_test_sequence',train_sequence)\n",
    "np.save('court_test_cluster_id',train_cluster_id)\n",
    "print(train_sequence.shape)\n",
    "print(train_cluster_id.shape)\n",
    "print(\"Speakers:\")\n",
    "print(set(train_cluster_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-03c87c85419c>\", line 20, in <module>\n",
      "    pool = Pool(NUM_PROCESSES)\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/context.py\", line 119, in Pool\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 158, in __init__\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 252, in _setup_queues\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/context.py\", line 112, in SimpleQueue\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 331, in __init__\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 517, in Pipe\n",
      "OSError: [Errno 24] Too many open files\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "OSError: [Errno 24] Too many open files\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from spectralcluster import SpectralClusterer\n",
    "import numpy as np\n",
    "import uisrnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_sequences = np.load('court_test_sequence.npy')\n",
    "test_cluster_ids = np.load('court_test_cluster_id.npy')\n",
    "test_size = 1500\n",
    "test_sequences = np.array([np.array(test_sequences[i:i + test_size]) for i in range(0, len(test_sequences), test_size)])\n",
    "test_cluster_ids = [list(test_cluster_ids[i:i + test_size]) for i in range(0,len(test_cluster_ids),test_size)]\n",
    "index = 1\n",
    "\n",
    "### MULTI\n",
    "from multiprocessing import Pool\n",
    "def spectral_parallel(sequence):\n",
    "    clusterer = SpectralClusterer(min_clusters=3,max_clusters=20,p_percentile=0.92,gaussian_blur_sigma=2.3, cosine=False)\n",
    "    labels = clusterer.predict(sequence)\n",
    "    return labels\n",
    "NUM_PROCESSES = 3\n",
    "pool = Pool(NUM_PROCESSES)\n",
    "results = pool.map(spectral_parallel, test_sequences)\n",
    "index = 1\n",
    "accuracy_lst = []\n",
    "for true_labels, predicted_labels in zip(test_cluster_ids, results):\n",
    "    print(\"######## TEST \" + str(index) + \" #######\")\n",
    "    print(\"Num of true labels:\" + str(len(set(true_labels))))\n",
    "    print(\"Num of predicted labels:\" + str(len(set(predicted_labels))))\n",
    "    accuracy = uisrnn.compute_sequence_match_accuracy(list(true_labels), list(predicted_labels))\n",
    "    accuracy_lst.append(accuracy)\n",
    "    print(\"Accuracy:\" + str(accuracy))\n",
    "    index += 1\n",
    "    f, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(15, 5))\n",
    "    ax1.scatter(range(len(true_labels)), true_labels, s=300, marker='|')\n",
    "    ax2.scatter(range(len(predicted_labels)), predicted_labels, s=300, marker='|')\n",
    "    plt.show()\n",
    "print('Average accuracy:' + str(np.mean(accuracy_lst)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/visualization.csv\n",
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-569138a635e1>\", line 2, in <module>\n",
      "    visualization(tmp_dir + 'visualization.csv', 3000)\n",
      "  File \"/Users/junhengwang/coop/diarization/dvector_vis.py\", line 66, in visualization\n",
      "  File \"/Users/junhengwang/coop/diarization/dvector_vis.py\", line 13, in csv_load\n",
      "OSError: [Errno 24] Too many open files: './tmp/visualization.csv'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "OSError: [Errno 24] Too many open files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread IPythonHistorySavingThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/history.py\", line 834, in run\n",
      "  File \"<decorator-gen-23>\", line 2, in writeout_cache\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/history.py\", line 58, in needs_sqlite\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/history.py\", line 780, in writeout_cache\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/history.py\", line 764, in _writeout_input_cache\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/iostream.py\", line 97, in _event_pipe\n",
      "AttributeError: '_thread._local' object has no attribute 'event_pipe'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "  File \"<decorator-gen-24>\", line 2, in run\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/history.py\", line 58, in needs_sqlite\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/history.py\", line 837, in run\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/iostream.py\", line 400, in write\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/iostream.py\", line 203, in schedule\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/iostream.py\", line 101, in _event_pipe\n",
      "  File \"/usr/local/lib/python3.7/site-packages/zmq/sugar/context.py\", line 146, in socket\n",
      "  File \"/usr/local/lib/python3.7/site-packages/zmq/sugar/socket.py\", line 59, in __init__\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 328, in zmq.backend.cython.socket.Socket.__init__\n",
      "zmq.error.ZMQError: Too many open files\n",
      "Unhandled exception in thread started by <bound method Thread._bootstrap of <HistorySavingThread(IPythonHistorySavingThread, started 123145433075712)>>\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files: './tmp/visualization.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "tmp_dir = './tmp/'\n",
    "visualization(tmp_dir + 'visualization.csv', 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation from spectral:\n",
    "\n",
    "1. Could not predicted the number of speakers correctly mostly because some speakers have too few dvectors. \n",
    "\n",
    "Observation from visualization:\n",
    "\n",
    "1. There is a big region of scatter, possibly due to noise\n",
    "\n",
    "2. The embedding model seems to be not robust enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4\n",
      "0.8493333333333334\n",
      "0.5906666666666667\n",
      "0.6333333333333333\n",
      "0.7966666666666666\n",
      "0.834\n",
      "0.8492871690427699\n",
      "Average accuracy:0.7588811948404617\n",
      "2.5\n",
      "0.8486666666666667\n",
      "0.5873333333333334\n",
      "0.6326666666666667\n",
      "0.796\n",
      "0.8346666666666667\n",
      "0.8492871690427699\n",
      "Average accuracy:0.7581034170626838\n",
      "2.6\n",
      "0.8506666666666667\n",
      "0.5886666666666667\n",
      "0.6326666666666667\n",
      "0.7946666666666666\n",
      "0.8326666666666667\n",
      "0.8533604887983707\n",
      "Average accuracy:0.7587823036886174\n",
      "2.7\n",
      "0.7033333333333334\n",
      "0.588\n",
      "0.6313333333333333\n",
      "0.794\n",
      "0.8306666666666667\n",
      "0.8513238289205702\n",
      "Average accuracy:0.7331095270423172\n",
      "2.8\n",
      "0.7046666666666667\n",
      "0.59\n",
      "0.6313333333333333\n",
      "0.792\n",
      "0.828\n",
      "0.8513238289205702\n",
      "Average accuracy:0.7328873048200949\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from spectralcluster import SpectralClusterer\n",
    "import numpy as np\n",
    "import uisrnn\n",
    "import matplotlib.pyplot as plt\n",
    "test_sequences = np.load('court_test_sequence.npy')\n",
    "test_cluster_ids = np.load('court_test_cluster_id.npy')\n",
    "test_size = 1500\n",
    "test_sequences = np.array([np.array(test_sequences[i:i + test_size]) for i in range(0, len(test_sequences), test_size)])\n",
    "test_cluster_ids = [list(test_cluster_ids[i:i + test_size]) for i in range(0,len(test_cluster_ids),test_size)]\n",
    "index = 1\n",
    "def spectral_para(sequence):\n",
    "    global gaussian_blur_sigma\n",
    "    clusterer = SpectralClusterer(min_clusters=3,max_clusters=20,p_percentile=0.92,gaussian_blur_sigma=gaussian_blur_sigma,cosine=False)\n",
    "    labels = clusterer.predict(sequence)\n",
    "    return labels\n",
    "gaussian_blur_sigma = 2.4\n",
    "for num in range(5):\n",
    "    gaussian_blur_sigma = 2.4 + 0.1*num\n",
    "    print(gaussian_blur_sigma)\n",
    "    NUM_PROCESSES = 3\n",
    "    pool = Pool(NUM_PROCESSES)\n",
    "    results = pool.map(spectral_para, test_sequences)\n",
    "    index = 1\n",
    "    accuracy_lst = []\n",
    "    for true_labels, predicted_labels in zip(test_cluster_ids, results):\n",
    "        accuracy = uisrnn.compute_sequence_match_accuracy(list(true_labels), list(predicted_labels))\n",
    "        print(accuracy)\n",
    "        accuracy_lst.append(accuracy)\n",
    "        index += 1\n",
    "        #f, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(15, 5))\n",
    "        #ax1.scatter(range(len(true_labels)), true_labels, s=300, marker='|')\n",
    "        #ax2.scatter(range(len(predicted_labels)), predicted_labels, s=300, marker='|')\n",
    "        #plt.show()\n",
    "    print('Average accuracy:' + str(np.mean(accuracy_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "#SPECTRAL SINGLE PRO\n",
    "accuracy_lst = []\n",
    "for sequence, cluster_ids in zip(test_sequences, test_cluster_ids):\n",
    "    print(\"######## TEST \" + str(index) + \" #######\")\n",
    "    print(\"Num of true labels:\" + str(len(set(cluster_ids))))\n",
    "    clusterer = SpectralClusterer(min_clusters=3,max_clusters=20,p_percentile=0.92,gaussian_blur_sigma=2)\n",
    "    labels = clusterer.predict(sequence)\n",
    "    print(\"Num of predicted labels:\" + str(len(set(labels))))\n",
    "    accuracy = uisrnn.compute_sequence_match_accuracy(list(cluster_ids), list(labels))\n",
    "    accuracy_lst.append(accuracy)\n",
    "    print(\"Accuracy:\" + str(accuracy))\n",
    "    index += 1\n",
    "    f, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(15, 5))\n",
    "    ax1.scatter(range(len(cluster_ids)), cluster_ids, s=300, marker='|')\n",
    "    ax2.scatter(range(len(labels)), labels, s=300, marker='|')\n",
    "    plt.show()\n",
    "print('Average accuracy:' + str(np.mean(accuracy_lst)))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
